Namespace(amsgrad=True, ann_path='../iu_xray/annotation.json', batch_size=16, beam_size=3, block_trigrams=1, bos_idx=0, d_ff=512, d_model=512, d_vf=2048, dataset_name='iu_xray', decoding_constraint=0, drop_prob_lm=0.5, dropout=0.1, early_stop=50, eos_idx=0, epochs=100, gamma=0.1, group_size=1, image_dir='../iu_xray/images/', logit_layers=1, lr_ed=0.0001, lr_scheduler='StepLR', lr_ve=5e-05, max_seq_length=60, monitor_metric='BLEU_4', monitor_mode='max', n_gpu=8, num_heads=8, num_layers=3, num_workers=2, optim='Adam', output_logsoftmax=1, pad_idx=0, record_dir='records/', resume=None, rm_d_model=512, rm_num_heads=8, rm_num_slots=3, sample_method='beam_search', sample_n=1, save_dir='results/iu_xray_debug', save_period=1, seed=9223, step_size=100, temperature=1.0, threshold=3, use_bn=0, visual_extractor='resnet101', visual_extractor_pretrained=True, weight_decay=5e-05)
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([16, 2, 3, 224, 224])
images.size() torch.Size([5, 2, 3, 224, 224])
Traceback (most recent call last):
  File "main.py", line 123, in <module>
    main()
  File "main.py", line 119, in main
    trainer.train()
  File "/fs03/bw83/donghao/R2Gen/modules/trainer.py", line 57, in train
    result = self._train_epoch(epoch)
  File "/fs03/bw83/donghao/R2Gen/modules/trainer.py", line 223, in _train_epoch
    output = self.model(images, mode='sample')
  File "/projects/bw83/dzha0062/conda_envs/R2Genv3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/projects/bw83/dzha0062/conda_envs/R2Genv3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 155, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/projects/bw83/dzha0062/conda_envs/R2Genv3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 165, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/projects/bw83/dzha0062/conda_envs/R2Genv3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 85, in parallel_apply
    output.reraise()
  File "/projects/bw83/dzha0062/conda_envs/R2Genv3/lib/python3.8/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
TypeError: Caught TypeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/projects/bw83/dzha0062/conda_envs/R2Genv3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 60, in _worker
    output = module(*input, **kwargs)
  File "/projects/bw83/dzha0062/conda_envs/R2Genv3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
TypeError: forward() got an unexpected keyword argument 'mode'

